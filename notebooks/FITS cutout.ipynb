{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from astropy.io.fits import HDUList\n",
    "from astropy.wcs import WCS\n",
    "from numpy import arcsinh\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.visualization import astropy_mpl_style\n",
    "from reproject import reproject_interp\n",
    "import aplpy\n",
    "from aplpy.rgb import make_rgb_cube\n",
    "import matplotlib.pyplot as pyplot\n",
    "from PIL import Image\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "import sdss_gz_data as sgd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1694112\r\n",
      "-rw-r--r--@ 1 will  staff  349816837 11 Mar 15:14 astromonical_data.csv.gz\r\n",
      "-rw-r--r--@ 1 will  staff   12447360 20 Jan 21:44 frame-g-000756-2-0427.fits\r\n",
      "-rw-r--r--@ 1 will  staff   12447360  8 Dec 12:20 frame-g-002141-3-0076.fits\r\n",
      "-rw-r--r--@ 1 will  staff   12447360 20 Jan 21:44 frame-i-000756-2-0427.fits\r\n",
      "-rw-r--r--@ 1 will  staff   12447360  8 Dec 12:20 frame-i-002141-3-0076.fits\r\n",
      "-rw-r--r--@ 1 will  staff   12447360 20 Jan 21:44 frame-r-000756-2-0427.fits\r\n",
      "-rw-r--r--@ 1 will  staff   12447360 20 Jan 14:14 frame-r-002141-3-0076.fits\r\n",
      "-rw-r--r--@ 1 will  staff  319952110 31 Jan 20:01 input.csv\r\n",
      "-rw-r--r--@ 1 will  staff    3409920  9 Dec 12:39 photoObj-002141-3-0076.fits\r\n",
      "-rw-r--r--  1 will  staff   36979200 11 Feb 19:42 rgb-000756-2-0427.fits\r\n",
      "-rw-r--r--  1 will  staff   12329280 11 Feb 19:42 rgb-000756-2-0427_2d.fits\r\n",
      "-rw-r--r--  1 will  staff   36933120 20 Jan 17:16 rgb-002141-3-0076.fits\r\n",
      "-rw-r--r--  1 will  staff   12314880 20 Jan 17:16 rgb-002141-3-0076_2d.fits\r\n"
     ]
    }
   ],
   "source": [
    "%ls -l data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_data = sgd.load_data('data/astromonical_data.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_data.objid = orig_data.objid.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = orig_data[['objid','run','rerun','camcol','field','obj','ra','dec','petroRad_r']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "objid         1237648702982979791\n",
       "run                           752\n",
       "rerun                         301\n",
       "camcol                          1\n",
       "field                         518\n",
       "obj                           207\n",
       "ra                        221.077\n",
       "dec                      -1.10511\n",
       "petroRad_r                4.75825\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = data[['run','camcol','field']].drop_duplicates(['run','camcol','field'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>camcol</th>\n",
       "      <th>field</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>756</td>\n",
       "      <td>2</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      run  camcol  field\n",
       "1103  756       2    427"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector = np.all([\n",
    "        fields.run == 756,\n",
    "        fields.camcol == 2,\n",
    "        fields.field == 427\n",
    "    ], axis=0)\n",
    "fields = fields[selector]\n",
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_rgb(data, sigma=1/3, gains=[0.9,1.1,1.8], gamma=0.1):\n",
    "    min = 0\n",
    "    max = np.max(data)\n",
    "\n",
    "    R_IDX = 0\n",
    "    G_IDX = 1\n",
    "    B_IDX = 2\n",
    "    \n",
    "    if min < 0:\n",
    "        data = data - min\n",
    "        max = max - min\n",
    "        min = 0\n",
    "\n",
    "    r = data[R_IDX].copy()\n",
    "    g = data[G_IDX].copy()\n",
    "    b = data[B_IDX].copy()\n",
    "\n",
    "    slope = 255 / arcsinh((max - min)/sigma)\n",
    "\n",
    "    mean = (r + g + b)/3\n",
    "    mean[mean < min] = 0\n",
    "    r[mean == 0] = 0\n",
    "    g[mean == 0] = 0\n",
    "    b[mean == 0] = 0\n",
    "    \n",
    "    scale = slope * arcsinh((mean - min) / sigma) / mean\n",
    "\n",
    "    r = (r * scale).astype(int)\n",
    "    g = (g * scale).astype(int)\n",
    "    b = (b * scale).astype(int)\n",
    "    \n",
    "    r = (r * gains[R_IDX]).astype(int)\n",
    "    g = (g * gains[G_IDX]).astype(int)\n",
    "    b = (b * gains[B_IDX]).astype(int)\n",
    "    \n",
    "    r += (gamma * (r - g)).astype(int)\n",
    "    b += (gamma * (b - g)).astype(int)\n",
    "\n",
    "    r[r < 0] = 0\n",
    "    r[r > 255] = 255\n",
    "    g[g < 0] = 0\n",
    "    g[g > 255] = 255\n",
    "    b[b < 0] = 0\n",
    "    b[b > 255] = 255\n",
    "    \n",
    "    result = np.empty(data.shape, dtype=np.uint8)\n",
    "    result[0] = r\n",
    "    result[1] = g\n",
    "    result[2] = b\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading fits/756/2/427/frame-i-000756-2-0427.fits\n",
      "Downloading fits/756/2/427/frame-r-000756-2-0427.fits\n",
      "Downloading fits/756/2/427/frame-g-000756-2-0427.fits\n",
      "Creating cutout for 1237648720693756176: {'run': 756, 'camcol': 2, 'field': 427, 'ra': 179.754212141942, 'dec': -0.545451447409319}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/will/Development/Astronomy/proposal/ENV/lib/python3.7/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating cutout for 1237648720693756035: {'run': 756, 'camcol': 2, 'field': 427, 'ra': 179.80368305327, 'dec': -0.523819565383534}\n",
      "Creating cutout for 1237648720693756115: {'run': 756, 'camcol': 2, 'field': 427, 'ra': 179.68640985059898, 'dec': -0.6029183904689069}\n",
      "Creating cutout for 1237648720693755918: {'run': 756, 'camcol': 2, 'field': 427, 'ra': 179.68929342839297, 'dec': -0.454379058425512}\n",
      "Creating cutout for 1237648720693756163: {'run': 756, 'camcol': 2, 'field': 427, 'ra': 179.71801538001802, 'dec': -0.530204164688646}\n"
     ]
    }
   ],
   "source": [
    "def save_cutout(obj, data):\n",
    "    from astropy.io import fits\n",
    "\n",
    "    filename = f'./data/obj-{obj.objid}.fits'\n",
    "    hdu = fits.PrimaryHDU(data)\n",
    "    hdu.writeto(filename, overwrite=True)\n",
    "\n",
    "def resize(data, size):\n",
    "    return np.array(Image.fromarray(data).resize((size, size), Image.BICUBIC))\n",
    "\n",
    "def download_fits(field):\n",
    "    from shutil import copy\n",
    "\n",
    "    filenames = np.empty(3, dtype=object)\n",
    "    for idx, band in enumerate(['i', 'r', 'g']):\n",
    "        file_dir = f'fits/{field.run}/{field.camcol}/{field.field}'\n",
    "        filename = f'frame-{band}-{field.run:06d}-{field.camcol}-{field.field:04d}.fits'\n",
    "\n",
    "        file = f'{file_dir}/{filename}'\n",
    "        outfile = f'./data/{filename}'\n",
    "        print(f'Downloading {file}')\n",
    "        copy(f'./data/{file}', outfile, follow_symlinks=True)\n",
    "        filenames[idx] = outfile\n",
    "\n",
    "    return filenames\n",
    "\n",
    "def isolate_image_extension(fits_file, extension):\n",
    "    '''\n",
    "        Saves the data + header of the specified extension as\n",
    "        new FITS file\n",
    "\n",
    "        input\n",
    "        ------\n",
    "        fits_file: file path to FITS image\n",
    "        extension: Number of HDU extension containing the image data\n",
    "    '''\n",
    "    from astropy.io import fits\n",
    "\n",
    "    header = fits.getheader(fits_file, extension)\n",
    "    data = fits.getdata(fits_file, extension)\n",
    "\n",
    "    fits.writeto(fits_file, data, header, overwrite=True)\n",
    "\n",
    "def make_data_cube(field, filenames):\n",
    "    for filename in filenames:\n",
    "        isolate_image_extension(filename, 0)\n",
    "\n",
    "    output = f'./data/rgb-{field.run:06d}-{field.camcol}-{field.field:04d}.fits'\n",
    "    \n",
    "    make_rgb_cube(filenames, output)\n",
    "    return output\n",
    "\n",
    "def save_png(obj, data, vmax):\n",
    "    from PIL import Image\n",
    "    filename = f'./data/{obj.objid}.png'\n",
    "    \n",
    "    data = data.copy()\n",
    "    # cropy image\n",
    "    data = data[:,106:318,106:308]\n",
    "\n",
    "    png_data = scale_rgb(data)\n",
    "    Image.fromarray(np.transpose(png_data)).transpose(Image.ROTATE_90).save(filename)\n",
    "\n",
    "def cutout_object_img(obj, data_cube_filename, sizing_ratio=7.8567420132):\n",
    "    def cutout_band(band, position, size, wcs):\n",
    "        from astropy.nddata import Cutout2D\n",
    "        \n",
    "        return Cutout2D(band,position=position,size=size, wcs=wcs)\n",
    "\n",
    "    from astropy.io import fits\n",
    "    from astropy.coordinates import SkyCoord, ICRS\n",
    "    import astropy.units as u\n",
    "    from astropy.nddata import Cutout2D\n",
    "\n",
    "    obj_hash = {\n",
    "        'run': obj.run,\n",
    "        'camcol': obj.camcol,\n",
    "        'field': obj.field,\n",
    "        'ra': obj.ra,\n",
    "        'dec': obj.dec\n",
    "    }\n",
    "    print(f'Creating cutout for {obj.objid}: {obj_hash}')\n",
    "    \n",
    "    angular_size = sizing_ratio * obj.petroRad_r\n",
    "    \n",
    "    fits_file = fits.open(data_cube_filename)\n",
    "    hdu = fits_file[0]\n",
    "    data = hdu.data\n",
    "    header = hdu.header\n",
    "    wcs = WCS(header, naxis=2)\n",
    "    vmax = np.max(data)\n",
    "    \n",
    "    position = SkyCoord(ra=obj.ra, dec=obj.dec, frame=ICRS, unit=u.deg)\n",
    "    cutout_size = u.Quantity((angular_size, angular_size), u.arcsec)\n",
    "    image_data = np.empty((3, 424, 424), dtype=float)\n",
    "    \n",
    "    for idx in range(3):\n",
    "        cutout = Cutout2D(data[idx], position=position, size=cutout_size, wcs=wcs)\n",
    "        image_data[idx] = resize(cutout.data, 424)\n",
    "    \n",
    "    # save data as a fits for the data cutout\n",
    "    save_cutout(obj, image_data)\n",
    "    \n",
    "    save_png(obj, image_data, vmax)\n",
    "\n",
    "for _, row in fields.iterrows():\n",
    "    filenames = download_fits(row)\n",
    "    data_cube_filename = make_data_cube(row, filenames)\n",
    "    \n",
    "    selector = np.all([\n",
    "        data.run == row['run'],\n",
    "        data.camcol == row['camcol'],\n",
    "        data.field == row['field']\n",
    "    ], axis=0)\n",
    "    \n",
    "    curr_field_data = data[selector]\n",
    "    for _, obj in curr_field_data.iterrows():\n",
    "        cutout_object_img(obj, data_cube_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-37cb5f09f21a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcombined_spiral\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspiralclock\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspiralanticlock\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medgeon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'galaxy_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNKNOWN_GALAXY_TYPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'combined_spiral'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_spiral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebiased_elliptical\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mCONFIDENCE_LEVEL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'galaxy_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mELLIPTICAL_GALAXY_TYPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_data' is not defined"
     ]
    }
   ],
   "source": [
    "data = input_data.copy()\n",
    "combined_spiral = data.spiralclock + data.spiralanticlock + data.edgeon\n",
    "data['galaxy_type'] = UNKNOWN_GALAXY_TYPE\n",
    "data['combined_spiral'] = combined_spiral\n",
    "data.loc[data.debiased_elliptical > CONFIDENCE_LEVEL, 'galaxy_type'] = ELLIPTICAL_GALAXY_TYPE\n",
    "data.loc[data.debiased_spiral > CONFIDENCE_LEVEL, 'galaxy_type'] = SPIRIAL_GALAXY_TYPE\n",
    "\n",
    "num_of_elliptical = data[data.galaxy_type == ELLIPTICAL_GALAXY_TYPE].size\n",
    "num_of_spirial = data[data.galaxy_type == SPIRIAL_GALAXY_TYPE].size\n",
    "num_of_unknown = data[data.galaxy_type == UNKNOWN_GALAXY_TYPE].size\n",
    "total_count = data.size\n",
    "\n",
    "print(num_of_elliptical / total_count)\n",
    "print(num_of_spirial / total_count)\n",
    "print(num_of_unknown / total_count)\n",
    "print(num_of_spirial / (num_of_elliptical + num_of_spirial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://skyserver.sdss.org/dr12/SkyserverWS/ImgCutout/getjpeg?ra=224.5941&dec=-1.09&width=512\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GZ_IMAGE_SIZE = 424\n",
    "BASE_CUTOUT_SCALE = 0.008\n",
    "\n",
    "def download_image(row, image_size=GZ_IMAGE_SIZE, padding_scale=1.0):\n",
    "    petroRad = row['petroRad_r']\n",
    "    ra = row['ra']\n",
    "    dec = row['dec']\n",
    "    scale = BASE_CUTOUT_SCALE * GZ_IMAGE_SIZE/image_size * petroRad * padding_scale\n",
    "\n",
    "    url = f'http://skyserver.sdss.org/dr15/SkyserverWS/ImgCutout/getjpeg?ra={ra}&dec={dec}&width={image_size}&height={image_size}&scale={scale}'\n",
    "    return Image.open(urlopen(url))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = download_image(data.loc[0])\n",
    "plt.imshow(img, cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = download_image(data.loc[0], image_size=224)\n",
    "plt.imshow(img, cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_size = 424\n",
    "small_size = 64\n",
    "\n",
    "scale = small_size/float(orig_size)\n",
    "small_img = img.resize((64,64), Image.ANTIALIAS)\n",
    "plt.imshow(small_img, cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_scale = np.random.uniform(0.9, 1.1)\n",
    "new_size = int(rand_scale * orig_size)\n",
    "new_size\n",
    "resized_img = img.resize((new_size, new_size), Image.ANTIALIAS)\n",
    "plt.imshow(resized_img, cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = (orig_size - 212)/2\n",
    "top = left\n",
    "right = (orig_size + 212)/2\n",
    "bottom = right\n",
    "\n",
    "cropped_image = img.crop((left, top, right, bottom))\n",
    "plt.imshow(cropped_image, cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_dimensions(curr_size, new_size, top_offset=0, left_offset=0):\n",
    "    top = int((curr_size - new_size)/2 + top_offset)\n",
    "    bottom = top + new_size\n",
    "    left = int((curr_size - new_size)/2 + left_offset)\n",
    "    right = left + new_size\n",
    "    \n",
    "    return (left, top, right, bottom)\n",
    "\n",
    "def centre_crop(img):\n",
    "#    return img.crop(crop_dimensions(image_size, crop_size))\n",
    "    (left, top, right, bottom) = crop_dimensions(image_size, crop_size)\n",
    "    return img[left:right,top:bottom,:]\n",
    "\n",
    "def create_crops(img, size=224):\n",
    "    (width, height) = img.size\n",
    "    imgs = []\n",
    "    \n",
    "    imgs.append(img.crop(crop_dimensions(width, size)))\n",
    "    # do the middle third range in the quadrant\n",
    "    max_offset = (width - size)/3\n",
    "    min_offset = max_offset / 2\n",
    "    for idx in range(0,4):\n",
    "        offset = np.random.uniform(min_offset, max_offset, 2)\n",
    "        if idx < 2:\n",
    "            offset[0] = -offset[0]\n",
    "        if idx % 2 == 0:\n",
    "            offset[1] = -offset[1]\n",
    "        \n",
    "        cropped_img = img.crop(crop_dimensions(width, size, top_offset=int(offset[0]), left_offset=int(offset[1])))\n",
    "        cropped_img.show()\n",
    "        imgs.append(cropped_img)\n",
    "\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(imgs, size=batch_size):\n",
    "    num_rows = int(np.ceil(size/3.0))\n",
    "    print(num_rows)\n",
    "    figsize_y = 5 * num_rows\n",
    "\n",
    "    fig = plt.figure(figsize=(20,figsize_y))\n",
    "    for idx in range(0, size):\n",
    "        img = imgs[idx]\n",
    "        # make scale between 0 and 1.0 plotting\n",
    "        img_min = img.min()\n",
    "        img_max = img.max()\n",
    "        img = (img - img_min) / (img_max - img_min)\n",
    "\n",
    "        fig.add_subplot(num_rows, 3, idx + 1)\n",
    "        plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "def augment_images(datagen, X_train, y_train):\n",
    "    imgs = X_train.copy()\n",
    "    if not datagen is None:\n",
    "        imgs = apply_augmentation(datagen, X_train, y_train)\n",
    "\n",
    "    result_imgs = np.empty((imgs.shape[0], crop_size, crop_size, 3))\n",
    "    for idx, img in enumerate(imgs):\n",
    "        result_imgs[idx] = centre_crop(img)\n",
    "        \n",
    "    plot_images(result_imgs)\n",
    "    return result_imgs    \n",
    "    \n",
    "def apply_augmentation(datagen, X_train, y_train):\n",
    "    # Convert to float32 in here\n",
    "    X_train = X_train.astype('float32')\n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    for X_batch, y_batch in datagen.flow(X_train, y_train, shuffle=False, batch_size=batch_size):\n",
    "        return X_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Image Cutouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 9\n",
    "image_size = 350\n",
    "crop_size = 224\n",
    "padding_scale = float(350)/crop_size\n",
    "\n",
    "X_train = np.empty((batch_size, image_size, image_size, 3), dtype=int)\n",
    "y_train = []\n",
    "\n",
    "for idx in range(0, batch_size):\n",
    "    img = download_image(data.loc[idx], image_size=image_size, padding_scale=padding_scale)\n",
    "    X_train[idx] = np.asarray(img)\n",
    "    y_train.append(data.loc[idx, 'galaxy_type'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_imgs = np.empty((8, batch_size, crop_size, crop_size, 3))\n",
    "augmented_imgs[0] = augment_images(None, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = np.moveaxis(X_train, 3, 0)\n",
    "fill = int(np.mean(channels))\n",
    "fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(featurewise_center=True,\n",
    "                             featurewise_std_normalization=True\n",
    "                            )\n",
    "augmented_imgs[1] = augment_images(datagen, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "                             rotation_range=180,fill_mode='constant',cval=fill\n",
    "                            )\n",
    "augmented_imgs[2] = augment_images(datagen, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = 0.1\n",
    "datagen = ImageDataGenerator(\n",
    "                             width_shift_range=shift,\n",
    "                             height_shift_range=shift,\n",
    "                             fill_mode='constant',\n",
    "                             cval=fill\n",
    "                            )\n",
    "\n",
    "augmented_imgs[3] = augment_images(datagen, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                             vertical_flip=True\n",
    "                            )\n",
    "augmented_imgs[4] = augment_images(datagen, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=0.1, fill_mode='constant')\n",
    "\n",
    "augmented_imgs[5] = augment_images(datagen, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samplewise normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(samplewise_center=True,\n",
    "                             samplewise_std_normalization=True\n",
    "                            )\n",
    "augmented_imgs[6] = augment_images(datagen, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = 0.1\n",
    "datagen = ImageDataGenerator(featurewise_center=True,\n",
    "                             featurewise_std_normalization=True,\n",
    "#                              samplewise_center=True,\n",
    "#                              samplewise_std_normalization=True,\n",
    "#                              width_shift_range=shift,\n",
    "#                              height_shift_range=shift,\n",
    "                             horizontal_flip=True,\n",
    "                             vertical_flip=True,\n",
    "                             fill_mode='constant',\n",
    "                             rotation_range=180,\n",
    "                             rescale=0.1,\n",
    "                             brightness_range=(0.9,1.1),\n",
    "                             cval=fill\n",
    "                            )\n",
    "\n",
    "augmented_imgs[7] = augment_images(datagen, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for augmentations in np.moveaxis(augmented_imgs, 0, 1):\n",
    "    plot_images(augmentations, size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_img = augmented_imgs[0]/255\n",
    "mod_img = augmented_imgs[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(mod_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
