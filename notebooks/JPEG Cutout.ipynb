{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from hyperopt import fmin\n",
    "from hyperopt import hp\n",
    "from hyperopt import tpe\n",
    "from hyperopt import Trials\n",
    "from hyperopt import STATUS_OK\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(bands=['u','g','i','r','z'], use_stokes=True, use_averages=False):\n",
    "    features = []\n",
    "\n",
    "    base_features = [\n",
    "                      'dered',\n",
    "                      'petroRad',\n",
    "                      'petroR50',\n",
    "                      'petroR90',\n",
    "                      'petro_R50_R90_ratio',\n",
    "                      'petroMag',\n",
    "                    ]\n",
    "    \n",
    "    stokes_features = [\n",
    "                      'stokes_q',\n",
    "                      'stokes_u',\n",
    "                      'stokes_p'\n",
    "                      ]\n",
    "\n",
    "    average_features = [\n",
    "        'avg_petro_rad',\n",
    "        'avg_petro_R50',\n",
    "        'avg_petro_R90',\n",
    "        'avg_petro_R50_R90_ratio'\n",
    "    ]\n",
    "    \n",
    "    average_stokes_features = [\n",
    "        'avg_stokes_q',\n",
    "        'avg_stokes_u',\n",
    "    ]\n",
    "    \n",
    "    valid_colour_indexes = [\n",
    "        'u_g_colour_index',\n",
    "        'g_r_colour_index',\n",
    "        'r_i_colour_index',\n",
    "        'i_z_colour_index',\n",
    "    ]\n",
    "    \n",
    "    for band in bands:\n",
    "        for base_feature in base_features:\n",
    "            feature = '{}_{}'.format(base_feature, band)\n",
    "            features.append(feature)\n",
    "            \n",
    "        if use_stokes:\n",
    "            for stokes_feature in stokes_features:\n",
    "                feature = '{}_{}'.format(stokes_feature, band)\n",
    "                features.append(feature)\n",
    "        \n",
    "        for band2 in bands:\n",
    "            feature = '{}_{}_colour_index'.format(band, band2)\n",
    "            if feature in valid_colour_indexes:\n",
    "                petro_feature = 'petro_{}'.format(feature)\n",
    "                features.append(feature)\n",
    "                features.append(petro_feature)\n",
    "\n",
    "    if use_averages:\n",
    "        features.extend(average_features)\n",
    "        if use_stokes:\n",
    "            features.extend(average_stokes_features)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIRIAL_GALAXY_TYPE    = 0\n",
    "ELLIPTICAL_GALAXY_TYPE = 1\n",
    "UNKNOWN_GALAXY_TYPE    = 2\n",
    "\n",
    "features = generate_features()\n",
    "\n",
    "target_column = 'galaxy_type'\n",
    "\n",
    "CONFIDENCE_LEVEL = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = pd.read_csv('data/input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = input_data.copy()\n",
    "combined_spiral = data.spiralclock + data.spiralanticlock + data.edgeon\n",
    "data['galaxy_type'] = UNKNOWN_GALAXY_TYPE\n",
    "data['combined_spiral'] = combined_spiral\n",
    "data.loc[data.debiased_elliptical > CONFIDENCE_LEVEL, 'galaxy_type'] = ELLIPTICAL_GALAXY_TYPE\n",
    "data.loc[data.debiased_spiral > CONFIDENCE_LEVEL, 'galaxy_type'] = SPIRIAL_GALAXY_TYPE\n",
    "\n",
    "num_of_elliptical = data[data.galaxy_type == ELLIPTICAL_GALAXY_TYPE].size\n",
    "num_of_spirial = data[data.galaxy_type == SPIRIAL_GALAXY_TYPE].size\n",
    "num_of_unknown = data[data.galaxy_type == UNKNOWN_GALAXY_TYPE].size\n",
    "total_count = data.size\n",
    "\n",
    "print(num_of_elliptical / total_count)\n",
    "print(num_of_spirial / total_count)\n",
    "print(num_of_unknown / total_count)\n",
    "print(num_of_spirial / (num_of_elliptical + num_of_spirial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://skyserver.sdss.org/dr12/SkyserverWS/ImgCutout/getjpeg?ra=224.5941&dec=-1.09&width=512\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GZ_IMAGE_SIZE = 424\n",
    "BASE_CUTOUT_SCALE = 0.008\n",
    "\n",
    "def download_image(row, image_size=GZ_IMAGE_SIZE, padding_scale=1.0):\n",
    "    petroRad = row['petroRad_r']\n",
    "    ra = row['ra']\n",
    "    dec = row['dec']\n",
    "    scale = BASE_CUTOUT_SCALE * GZ_IMAGE_SIZE/image_size * petroRad * padding_scale\n",
    "\n",
    "    url = f'http://skyserver.sdss.org/dr15/SkyserverWS/ImgCutout/getjpeg?ra={ra}&dec={dec}&width={image_size}&height={image_size}&scale={scale}'\n",
    "    return Image.open(urlopen(url))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = download_image(data.loc[0])\n",
    "plt.imshow(img, cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = download_image(data.loc[0], image_size=224)\n",
    "plt.imshow(img, cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_size = 424\n",
    "small_size = 64\n",
    "\n",
    "scale = small_size/float(orig_size)\n",
    "small_img = img.resize((64,64), Image.ANTIALIAS)\n",
    "plt.imshow(small_img, cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_scale = np.random.uniform(0.9, 1.1)\n",
    "new_size = int(rand_scale * orig_size)\n",
    "new_size\n",
    "resized_img = img.resize((new_size, new_size), Image.ANTIALIAS)\n",
    "plt.imshow(resized_img, cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = (orig_size - 212)/2\n",
    "top = left\n",
    "right = (orig_size + 212)/2\n",
    "bottom = right\n",
    "\n",
    "cropped_image = img.crop((left, top, right, bottom))\n",
    "plt.imshow(cropped_image, cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_dimensions(curr_size, new_size, top_offset=0, left_offset=0):\n",
    "    top = int((curr_size - new_size)/2 + top_offset)\n",
    "    bottom = top + new_size\n",
    "    left = int((curr_size - new_size)/2 + left_offset)\n",
    "    right = left + new_size\n",
    "    \n",
    "    return (left, top, right, bottom)\n",
    "\n",
    "def centre_crop(img):\n",
    "#    return img.crop(crop_dimensions(image_size, crop_size))\n",
    "    (left, top, right, bottom) = crop_dimensions(image_size, crop_size)\n",
    "    return img[left:right,top:bottom,:]\n",
    "\n",
    "def create_crops(img, size=224):\n",
    "    (width, height) = img.size\n",
    "    imgs = []\n",
    "    \n",
    "    imgs.append(img.crop(crop_dimensions(width, size)))\n",
    "    # do the middle third range in the quadrant\n",
    "    max_offset = (width - size)/3\n",
    "    min_offset = max_offset / 2\n",
    "    for idx in range(0,4):\n",
    "        offset = np.random.uniform(min_offset, max_offset, 2)\n",
    "        if idx < 2:\n",
    "            offset[0] = -offset[0]\n",
    "        if idx % 2 == 0:\n",
    "            offset[1] = -offset[1]\n",
    "        \n",
    "        cropped_img = img.crop(crop_dimensions(width, size, top_offset=int(offset[0]), left_offset=int(offset[1])))\n",
    "        cropped_img.show()\n",
    "        imgs.append(cropped_img)\n",
    "\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(imgs, size=batch_size):\n",
    "    num_rows = int(np.ceil(size/3.0))\n",
    "    print(num_rows)\n",
    "    figsize_y = 5 * num_rows\n",
    "\n",
    "    fig = plt.figure(figsize=(20,figsize_y))\n",
    "    for idx in range(0, size):\n",
    "        img = imgs[idx]\n",
    "        # make scale between 0 and 1.0 plotting\n",
    "        img_min = img.min()\n",
    "        img_max = img.max()\n",
    "        img = (img - img_min) / (img_max - img_min)\n",
    "\n",
    "        fig.add_subplot(num_rows, 3, idx + 1)\n",
    "        plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "def augment_images(datagen, X_train, y_train):\n",
    "    imgs = X_train.copy()\n",
    "    if not datagen is None:\n",
    "        imgs = apply_augmentation(datagen, X_train, y_train)\n",
    "\n",
    "    result_imgs = np.empty((imgs.shape[0], crop_size, crop_size, 3))\n",
    "    for idx, img in enumerate(imgs):\n",
    "        result_imgs[idx] = centre_crop(img)\n",
    "        \n",
    "    plot_images(result_imgs)\n",
    "    return result_imgs    \n",
    "    \n",
    "def apply_augmentation(datagen, X_train, y_train):\n",
    "    # Convert to float32 in here\n",
    "    X_train = X_train.astype('float32')\n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    for X_batch, y_batch in datagen.flow(X_train, y_train, shuffle=False, batch_size=batch_size):\n",
    "        return X_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Image Cutouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 9\n",
    "image_size = 350\n",
    "crop_size = 224\n",
    "padding_scale = float(350)/crop_size\n",
    "\n",
    "X_train = np.empty((batch_size, image_size, image_size, 3), dtype=int)\n",
    "y_train = []\n",
    "\n",
    "for idx in range(0, batch_size):\n",
    "    img = download_image(data.loc[idx], image_size=image_size, padding_scale=padding_scale)\n",
    "    X_train[idx] = np.asarray(img)\n",
    "    y_train.append(data.loc[idx, 'galaxy_type'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_imgs = np.empty((8, batch_size, crop_size, crop_size, 3))\n",
    "augmented_imgs[0] = augment_images(None, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = np.moveaxis(X_train, 3, 0)\n",
    "fill = int(np.mean(channels))\n",
    "fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(featurewise_center=True,\n",
    "                             featurewise_std_normalization=True\n",
    "                            )\n",
    "augmented_imgs[1] = augment_images(datagen, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "                             rotation_range=180,fill_mode='constant',cval=fill\n",
    "                            )\n",
    "augmented_imgs[2] = augment_images(datagen, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = 0.1\n",
    "datagen = ImageDataGenerator(\n",
    "                             width_shift_range=shift,\n",
    "                             height_shift_range=shift,\n",
    "                             fill_mode='constant',\n",
    "                             cval=fill\n",
    "                            )\n",
    "\n",
    "augmented_imgs[3] = augment_images(datagen, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                             vertical_flip=True\n",
    "                            )\n",
    "augmented_imgs[4] = augment_images(datagen, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=0.1, fill_mode='constant')\n",
    "\n",
    "augmented_imgs[5] = augment_images(datagen, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samplewise normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(samplewise_center=True,\n",
    "                             samplewise_std_normalization=True\n",
    "                            )\n",
    "augmented_imgs[6] = augment_images(datagen, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = 0.1\n",
    "datagen = ImageDataGenerator(featurewise_center=True,\n",
    "                             featurewise_std_normalization=True,\n",
    "#                              samplewise_center=True,\n",
    "#                              samplewise_std_normalization=True,\n",
    "#                              width_shift_range=shift,\n",
    "#                              height_shift_range=shift,\n",
    "                             horizontal_flip=True,\n",
    "                             vertical_flip=True,\n",
    "                             fill_mode='constant',\n",
    "                             rotation_range=180,\n",
    "                             rescale=0.1,\n",
    "                             brightness_range=(0.9,1.1),\n",
    "                             cval=fill\n",
    "                            )\n",
    "\n",
    "augmented_imgs[7] = augment_images(datagen, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for augmentations in np.moveaxis(augmented_imgs, 0, 1):\n",
    "    plot_images(augmentations, size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_img = augmented_imgs[0]/255\n",
    "mod_img = augmented_imgs[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(mod_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
